# ===========================================
# TOKAMAK ARCHITECT BOT - Environment Config
# ===========================================

# Tokamak AI Gateway (LLM backend)
TOKAMAK_AI_BASE_URL=https://api.ai.tokamak.network
TOKAMAK_AI_API_KEY=your-api-key-here

# Chat Model
# Default: Qwen3 80B Next (served via Tokamak AI Gateway)
# Other examples (if enabled in the gateway):
# - qwen3-235b
# - claude-sonnet-4.5
# - claude-opus-4.5
# - claude-opus-4-6
# - claude-haiku-4.5
CHAT_MODEL=qwen3-80b-next

# ===========================================
# EMBEDDING PROVIDER CONFIGURATION
# ===========================================
# Options: "local", "openai", "tokamak"
#
# "local"   - Uses sentence-transformers (free, no API needed)
# "openai"  - Uses OpenAI embeddings API (needs OPENAI_API_KEY)
# "tokamak" - Uses Tokamak Gateway embeddings (if available)
#
EMBEDDING_PROVIDER=local

# Local Embedding Model (when EMBEDDING_PROVIDER=local)
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2

# OpenAI Embeddings (when EMBEDDING_PROVIDER=openai)
# OPENAI_API_KEY=sk-your-openai-key
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Tokamak Embeddings (when EMBEDDING_PROVIDER=tokamak)
# TOKAMAK_EMBEDDING_MODEL=text-embedding-ada-002

# ===========================================
# VECTOR DATABASE
# ===========================================
CHROMA_PERSIST_DIR=./data/chroma_db
CHROMA_COLLECTION_NAME=tokamak_docs

# ===========================================
# SERVER CONFIG
# ===========================================
HOST=0.0.0.0
PORT=8001
LOG_LEVEL=INFO

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# ===========================================
# RAG CONFIG
# ===========================================
# Number of documents to retrieve for context
RAG_TOP_K=4

# Chunk size for document splitting
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
